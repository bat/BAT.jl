{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BAT.jl Tutorial\n",
    "\n",
    "This tutorial demonstrates a simple application of BAT.jl: A Bayesian fit\n",
    "of a histogram with two Gaussian peaks.\n",
    "\n",
    "\n",
    "\n",
    "Note: This tutorial is somewhat verbose, as it aims to be easy to follow for\n",
    "users who are new to Julia. For the same reason, we deliberately avoid making\n",
    "use of Julia features like\n",
    "[closures](https://docs.julialang.org/en/v1/devdocs/functions/#Closures-1),\n",
    "[anonymous functions](https://docs.julialang.org/en/v1/manual/functions/index.html#man-anonymous-functions-1),\n",
    "[broadcasting syntax](https://docs.julialang.org/en/v1/manual/arrays/index.html#Broadcasting-1),\n",
    "[performance annotations](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-annotations-1),\n",
    "etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input Data Generation\n",
    "\n",
    "First, let's generate some synthetic data to fit. We'll need the Julia\n",
    "standard-library packages\n",
    "[\"Random\"](https://docs.julialang.org/en/v1/stdlib/Random/),\n",
    "[\"LinearAlgebra\"](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/)\n",
    "and [\"Statistics\"](https://docs.julialang.org/en/v1/stdlib/Statistics/),\n",
    "as well as the packages\n",
    "[\"Distributions\"](https://juliastats.org/Distributions.jl/stable/)\n",
    "and [\"StatsBase\"](https://juliastats.org/StatsBase.jl/stable/):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Random, LinearAlgebra, Statistics, Distributions, StatsBase"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the underlying truth of our input data/histogram, let us choose an\n",
    "non-normalized probability density composed of two Gaussian peaks with a peak\n",
    "area of 500 and 1000, a mean of -1.0 and 2.0 and a standard error of 0.5"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "data = vcat(\n",
    "    rand(Normal(-1.0, 0.5), 500),\n",
    "    rand(Normal( 2.0, 0.5), 1000)\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "resulting in a vector of floating-point numbers:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "typeof(data) == Vector{Float64}"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll create a histogram of that data, this histogram will serve as\n",
    "the input for the Bayesian fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "hist = append!(Histogram(-2:0.1:4), data)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the Julia [\"Plots\"](http://docs.juliaplots.org/latest/) package"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "we can plot the histogram:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    normalize(hist, mode=:density),\n",
    "    st = :steps, label = \"Data\",\n",
    "    title = \"Data\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's define our fit function - the function that we expect to describe the\n",
    "data histogram, at each x-Axis position `x`, depending on a given set `p` of\n",
    "model parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function fit_function(p::NamedTuple{(:a, :mu, :sigma)}, x::Real)\n",
    "    p.a[1] * pdf(Normal(p.mu[1], p.sigma), x) +\n",
    "    p.a[2] * pdf(Normal(p.mu[2], p.sigma), x)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The fit parameters (model parameters) `a` (peak areas) and `mu` (peak means)\n",
    "are vectors, parameter `sigma` (peak width) is a scalar, we assume it's the\n",
    "same for both Gaussian peaks.\n",
    "\n",
    "The true values for the model/fit parameters are the values we used to\n",
    "generate the data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "true_par_values = (a = [500, 1000], mu = (-1.0, 2.0), sigma = 0.5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's visually compare the histogram and the fit function, using these true\n",
    "parameter values, to make sure everything is set up correctly:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    normalize(hist, mode=:density),\n",
    "    st = :steps, label = \"Data\",\n",
    "    title = \"Data and True Statistical Model\"\n",
    ")\n",
    "plot!(\n",
    "    -4:0.01:4, x -> fit_function(true_par_values, x),\n",
    "    label = \"Truth\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bayesian Fit\n",
    "\n",
    "Now we'll perform a Bayesian fit of the generated histogram, using BAT,\n",
    "to infer the model parameters from the data histogram.\n",
    "\n",
    "In addition to the Julia packages loaded above, we need BAT itself, as\n",
    "well as [IntervalSets](https://github.com/JuliaMath/IntervalSets.jl):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BAT, IntervalSets"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Likelihood Definition\n",
    "\n",
    "First, we need to define the likelihood (function) for our problem.\n",
    "\n",
    "BAT represents densities like likelihoods and priors as subtypes of\n",
    "`BAT.AbstractDensity`. Custom likelihood can be defined by\n",
    "creating a new subtype of `AbstractDensity` and by implementing (at minimum)\n",
    "`BAT.eval_logval_unchecked` for that type - in complex uses cases, this may\n",
    "become necessary. Typically, however, it is sufficient to define a custom\n",
    "likelihood as a simple function that returns the log-likelihood value for\n",
    "a given set of parameters. BAT will automatically convert such a\n",
    "likelihood function into a subtype of `AbstractDensity`.\n",
    "\n",
    "For performance reasons, functions should [not access global variables\n",
    "directly] (https://docs.julialang.org/en/v1/manual/performance-tips/index.html#Avoid-global-variables-1).\n",
    "So we'll use an [anonymous function](https://docs.julialang.org/en/v1/manual/functions/#man-anonymous-functions-1)\n",
    "inside of a [let-statement](https://docs.julialang.org/en/v1/base/base/#let)\n",
    "to capture the value of the global variable `hist` in a local variable `h`\n",
    "(and to shorten function name `fit_function` to `f`, purely for\n",
    "convenience). The likelihood function wraps it's result in a `LogDVal`\n",
    "to indicate that it returns a log-likelihood value:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "likelihood = let h = hist, f = fit_function\n",
    "    # Histogram counts for each bin as an array:\n",
    "    observed_counts = h.weights\n",
    "\n",
    "    # Histogram binning:\n",
    "    bin_edges = h.edges[1]\n",
    "    bin_edges_left = bin_edges[1:end-1]\n",
    "    bin_edges_right = bin_edges[2:end]\n",
    "    bin_widths = bin_edges_right - bin_edges_left\n",
    "    bin_centers = (bin_edges_right + bin_edges_left) / 2\n",
    "\n",
    "    params -> begin\n",
    "        # Log-likelihood for a single bin:\n",
    "        function bin_log_likelihood(i)\n",
    "            # Simple mid-point rule integration of fit function `f` over bin:\n",
    "            expected_counts = bin_widths[i] * f(params, bin_centers[i])\n",
    "            logpdf(Poisson(expected_counts), observed_counts[i])\n",
    "        end\n",
    "\n",
    "        # Sum log-likelihood over bins:\n",
    "        idxs = eachindex(observed_counts)\n",
    "        ll_value = bin_log_likelihood(idxs[1])\n",
    "        for i in idxs[2:end]\n",
    "            ll_value += bin_log_likelihood(i)\n",
    "        end\n",
    "\n",
    "        # Wrap `ll_value` in `LogDVal` so BAT knows it's a log density-value.\n",
    "        return LogDVal(ll_value)\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "BAT makes use of Julia's parallel programming facilities if possible, e.g.\n",
    "to run multiple Markov chains in parallel. Therefore, log-likelihood\n",
    "(and other) code must be thread-safe. Mark non-thread-safe code with\n",
    "`@critical` (provided by Julia package `ParallelProcessingTools`).\n",
    "\n",
    "Support for automatic parallelization across multiple (local and remote)\n",
    "Julia processes is planned, but not implemented yet.\n",
    "\n",
    "Note that Julia currently starts only a single thread by default. Set the\n",
    "the environment variable\n",
    "[`JULIA_NUM_THREADS`](https://docs.julialang.org/en/v1/manual/environment-variables/#JULIA_NUM_THREADS-1)\n",
    "to specify the desired number of Julia threads."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can evaluate `likelihood`, e.g. for the true parameter values:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "likelihood(true_par_values)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prior Definition\n",
    "\n",
    "Next, we need to choose a sensible prior for the fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using ValueShapes\n",
    "\n",
    "prior = NamedTupleDist(\n",
    "    a = [Weibull(1.1, 5000), Weibull(1.1, 5000)],\n",
    "    mu = [-2.0..0.0, 1.0..3.0],\n",
    "    sigma = Weibull(1.2, 2)\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general, BAT allows instances of any subtype of `AbstractDensity` to\n",
    "be uses as a prior, as long as a sampler is defined for it. This way, users\n",
    "may implement complex application-specific priors. You can also\n",
    "use `convert(AbstractDensity, distribution)` to convert any\n",
    "continuous multivariate `Distributions.Distribution` to a\n",
    "`BAT.AbstractDensity` that can be used as a prior (or likelihood).\n",
    "\n",
    "The prior also implies the shapes of the parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "parshapes = varshape(prior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "These will come in handy later on, e.g. to access (the posterior\n",
    "distribution of) individual parameter values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayesian Model Definition\n",
    "\n",
    "Given the likelihood and prior definition, a `BAT.PosteriorDensity` is simply\n",
    "defined via"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "posterior = PosteriorDensity(likelihood, prior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameter Space Exploration via MCMC\n",
    "\n",
    "We can now use Markov chain Monte Carlo (MCMC) to explore the space of\n",
    "possible parameter values for the histogram fit.\n",
    "\n",
    "To increase the verbosity level of BAT logging output, you may want to set\n",
    "the Julia logging level for BAT to debug via `ENV[\"JULIA_DEBUG\"] = \"BAT\"`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ENV[\"JULIA_DEBUG\"] = \"BAT\""
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can generate a set of MCMC samples via `bat_sample`. We'll\n",
    "use 4 MCMC chains with 10^5 MC steps in each chain (after tuning/burn-in):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "samples = bat_sample(posterior, MCMCSampling(mcalg = MetropolisHastings(), nsteps = 10^5, nchains = 4)).result\n",
    "nothing # hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construct a `SampledDensity` to get a quick overview of the properties\n",
    "of the sampled posterior, estimates of the fit parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "SampledDensity(posterior, samples)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's calculate some statistics on the posterior samples:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "println(\"Truth: $true_par_values\")\n",
    "println(\"Mode: $(mode(samples))\")\n",
    "println(\"Mean: $(mean(samples))\")\n",
    "println(\"Stddev: $(std(samples))\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Internally, BAT often needs to represent variates as flat real-valued\n",
    "vectors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "unshaped.(samples).v"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "BAT uses [ValueShapes.jl](https://github.com/oschulz/ValueShapes.jl)\n",
    "to implement a dual view of variate values in both shaped and unshaped form,\n",
    "based on shape inferred from the prior and propagated to the posterior.\n",
    "Shaped and unshaped samples are views of the same data in memory.\n",
    "The variate/parameter shape can be accessed via"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "parshapes = varshape(posterior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The statisics above (mode, mean and std-dev) are presented in shaped form.\n",
    "However, it's not possible to represent statistics with matrix shape, e.g.\n",
    "the parameter covariance matrix, this way. So the covariance has to be\n",
    "accessed in unshaped form:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "par_cov = cov(unshaped.(samples))\n",
    "println(\"Covariance: $par_cov\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our `parshapes` is a `NamedTupleShape`. It's properties (i.e. individual\n",
    "parameter accessors) can be used as indices to query the covariance between\n",
    "specific parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "par_cov[parshapes.mu, parshapes.sigma]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization of Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "BAT.jl comes with an extensive set of plotting recipes for\n",
    "[\"Plots.jl\"] (http://docs.juliaplots.org/latest/).\n",
    "We can plot the marginalized distribution for a single parameter (e.g.\n",
    "parameter 3, i.e. μ[1]):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    samples, :(mu[1]),\n",
    "    mean = true, std = true, globalmode = true, marginalmode = true,\n",
    "    nbins = 50, title = \"Marginalized Distribution for mu[1]\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "or plot the marginalized distribution for a pair of parameters (e.g.\n",
    "parameters 3 and 5, i.e. μ[1] and σ), including information from the parameter\n",
    "stats:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    samples, (:(mu[1]), :sigma),\n",
    "    mean = true, std = true, globalmode = true, marginalmode = true,\n",
    "    nbins = 50, title = \"Marginalized Distribution for mu[1] and sigma\"\n",
    ")\n",
    "plot!(BAT.MCMCBasicStats(samples), (3, 5))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also create an overview plot of the marginalized distribution for all\n",
    "pairs of parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    samples,\n",
    "    mean = false, std = false, globalmode = true, marginalmode = false,\n",
    "    nbins = 50\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Integration with Tables.jl"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`DensitySamplesVector` supports the\n",
    "[Tables.jl](https://github.com/JuliaData/Tables.jl)\n",
    "interface, so it is a table itself. We can also convert it to other table\n",
    "types, e.g. a\n",
    "[`TypedTables.Table`](http://blog.roames.com/TypedTables.jl/stable/):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using TypedTables\n",
    "\n",
    "tbl = Table(samples)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "or a [`DataFrames.DataFrame`](https://github.com/JuliaData/DataFrames.jl),\n",
    "etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison of Truth and Best Fit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a final step, we retrieve the parameter values at the mode, representing\n",
    "the best-fit parameters"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "samples_mode = mode(samples)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Like the samples themselves, the result can be viewed in both shaped and\n",
    "unshaped form. `samples_mode` is presented as a 0-dimensional array that\n",
    "contains a NamedTuple, this representation preserves the shape information:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "samples_mode[] isa NamedTuple\n",
    "\n",
    "unshaped(samples_mode)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`samples_mode` is only an estimate of the mode of the posterior\n",
    "distribution. It can be further refined using `bat_findmode`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "findmode_result = bat_findmode(posterior, MaxDensityNelderMead(init = ExplicitInit([samples_mode])))\n",
    "\n",
    "fit_par_values = findmode_result.result[]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot the data and fit function given the true parameters and MCMC samples"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(-4:0.01:4, fit_function, samples)\n",
    "\n",
    "plot!(\n",
    "    normalize(hist, mode=:density),\n",
    "    color=1, linewidth=2, fillalpha=0.0,\n",
    "    st = :steps, fill=false, label = \"Data\",\n",
    "    title = \"Data, True Model and Best Fit\"\n",
    ")\n",
    "\n",
    "plot!(-4:0.01:4, x -> fit_function(true_par_values, x), color=4, label = \"Truth\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-grained control\n",
    "\n",
    "BAT provides fine-grained control over the MCMC algorithm options, the\n",
    "MCMC chain initialization, tuning/burn-in strategy and convergence testing.\n",
    "All option value used in the following are the default values, any or all\n",
    "may be omitted."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll sample using the The Metropolis-Hastings MCMC algorithm:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mcmcalgo = MetropolisHastings(\n",
    "    weighting = RepetitionWeighting(),\n",
    "    tuning = AdaptiveMHTuning()\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "BAT requires a counter-based random number generator (RNG), since it\n",
    "partitions the RNG space over the MCMC chains. This way, a single RNG seed\n",
    "is sufficient for all chains and results are reproducible even under\n",
    "parallel execution. By default, BAT uses a Philox4x RNG initialized with a\n",
    "random seed drawn from the\n",
    "[system entropy pool](https://docs.julialang.org/en/v1/stdlib/Random/index.html#Random.RandomDevice):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Random123\n",
    "rng = Philox4x()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, `MetropolisHastings()` uses the following options.\n",
    "\n",
    "For Markov chain initialization:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "init = MCMCChainPoolInit()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the MCMC burn-in procedure:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "burnin = MCMCMultiCycleBurnin()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For convergence testing:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "convergence = BrooksGelmanConvergence()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To generate MCMC samples with explicit control over all options, use\n",
    "something like"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "samples = bat_sample(\n",
    "    rng, posterior,\n",
    "    MCMCSampling(\n",
    "        mcalg = mcmcalgo,\n",
    "        nchains = 4,\n",
    "        nsteps = 10^5,\n",
    "        init = init,\n",
    "        burnin = burnin,\n",
    "        convergence = convergence,\n",
    "        strict = true,\n",
    "        store_burnin = false,\n",
    "        nonzero_weights = true,\n",
    "        callback = (x...) -> nothing\n",
    "    )\n",
    ").result\n",
    "nothing # hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving result data to files\n",
    "\n",
    "The package [FileIO.jl](https://github.com/JuliaIO/FileIO.jl)(in conjuction\n",
    "with [JLD2.jl](https://github.com/JuliaIO/JLD2.jl)) offers a convenient way\n",
    "to store results like posterior samples to file:\n",
    "\n",
    "```julia\n",
    "using FileIO\n",
    "FileIO.save(\"results.jld2\", Dict(\"samples\" => samples))\n",
    "```\n",
    "\n",
    "JLD2 persists the full information (including value shapes), so you can\n",
    "reload exactly the same data into memory in a new Julia session via\n",
    "\n",
    "```julia\n",
    "using FileIO, BAT\n",
    "samples = FileIO.load(\"results.jld2\", \"samples\")\n",
    "```\n",
    "\n",
    "provided you use compatible versions of BAT and it's dependencies. Note that\n",
    "JLD2 is *not* a long-term stable file format. Also note that this functionality\n",
    "is provided by FileIO.jl and JLD2.jl and not part of the BAT API itself.\n",
    "\n",
    "BAT.jl itself can write samples to standard HDF5 files in a form suitable for\n",
    "long-term storage (via [HDF5.jl](https://github.com/JuliaIO/HDF5.jl)):\n",
    "\n",
    "```julia\n",
    "import HDF5\n",
    "bat_write(\"results.h5\", samples)\n",
    "```\n",
    "\n",
    "The resulting files have an intuitive HDF5 layout and can be read with the\n",
    "standard HDF5 libraries, so they are easily accessible from other programming\n",
    "languages as well. Not all value shape information can be preserved, though.\n",
    "To read BAT.jl HDF5 sample data, use\n",
    "\n",
    "```julia\n",
    "using BAT\n",
    "import HDF5\n",
    "samples = bat_read(\"results.h5\").result\n",
    "```\n",
    "\n",
    "BAT.jl's HDF5 file format may evolve over time, but future versions of BAT.jl\n",
    "will be able to read HDF5 sample data written by this version of BAT.jl."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
