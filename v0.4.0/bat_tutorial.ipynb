{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# BAT.jl Tutorial\n",
    "\n",
    "This tutorial demonstrates a simple application of BAT.jl: A Bayesian fit\n",
    "of a histogram with two Gaussian peaks.\n",
    "\n",
    "\n",
    "\n",
    "Note: This tutorial is somewhat verbose, as it aims to be easy to follow for\n",
    "users who are new to Julia. For the same reason, we deliberately avoid making\n",
    "use of Julia features like\n",
    "[closures](https://docs.julialang.org/en/v1/devdocs/functions/#Closures-1),\n",
    "[anonymous functions](https://docs.julialang.org/en/v1/manual/functions/index.html#man-anonymous-functions-1),\n",
    "[broadcasting syntax](https://docs.julialang.org/en/v1/manual/arrays/index.html#Broadcasting-1),\n",
    "[performance annotations](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-annotations-1),\n",
    "etc."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Input Data Generation\n",
    "\n",
    "First, let's generate some synthetic data to fit. We'll need the Julia\n",
    "standard-library packages\n",
    "[\"Random\"](https://docs.julialang.org/en/v1/stdlib/Random/),\n",
    "[\"LinearAlgebra\"](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/)\n",
    "and [\"Statistics\"](https://docs.julialang.org/en/v1/stdlib/Statistics/),\n",
    "as well as the packages\n",
    "[\"Distributions\"](https://juliastats.github.io/Distributions.jl/stable/)\n",
    "and [\"StatsBase\"](http://juliastats.github.io/StatsBase.jl/stable/):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Random, LinearAlgebra, Statistics, Distributions, StatsBase"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "As the underlying truth of our input data/histogram, let us choose an\n",
    "non-normalized probability density composed of two Gaussian peaks with a peak\n",
    "area of 500 and 1000, a mean of -1.0 and 2.0 and a standard error of 0.5"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "data = vcat(\n",
    "    rand(Normal(-1.0, 0.5), 500),\n",
    "    rand(Normal( 2.0, 0.5), 1000)\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "resulting in a vector of floating-point numbers:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "typeof(data) == Vector{Float64}"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Next, we'll create a histogram of that data, this histogram will serve as\n",
    "the input for the Bayesian fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "hist = append!(Histogram(-2:0.1:4), data)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Using the Julia [\"Plots\"](http://docs.juliaplots.org/latest/) package"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "we can plot the histogram:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    normalize(hist, mode=:density),\n",
    "    st = :steps, label = \"Data\",\n",
    "    title = \"Data\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "The package [\"EponymTuples\"](https://github.com/tpapp/EponymTuples.jl)\n",
    "provides a very useful macro `@eponymargs`: It makes it easy to define\n",
    "functions that take named tuples as arguments and unpack them."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using EponymTuples"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "This comes in handy for the definition of ou fit function - the function\n",
    "that we expect to describes the data histogram (depending on some model\n",
    "parameters):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function fit_function(@eponymargs(a, mu, sigma), x::Real)\n",
    "    a[1] * pdf(Normal(mu[1], sigma), x) +\n",
    "    a[2] * pdf(Normal(mu[2], sigma), x)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "The fit parameters (model parameters) `a` (peak areas) and `mu` (peak means)\n",
    "are vectors, parameter `sigma` (peak width) is a scalar, we assume it's the\n",
    "same for both Gaussian peaks.\n",
    "\n",
    "The true values for the model/fit parameters are:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "true_par_values = (a = [500, 1000], mu = (-1.0, 2.0), sigma = 0.5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's visually compare the histogram and the fit function, using the true\n",
    "parameter values, to make sure everything is set up correctly:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    normalize(hist, mode=:density),\n",
    "    st = :steps, label = \"Data\",\n",
    "    title = \"Data and True Statistical Model\"\n",
    ")\n",
    "plot!(\n",
    "    -4:0.01:4, x -> fit_function(true_par_values, x),\n",
    "    label = \"Truth\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Bayesian Fit\n",
    "\n",
    "Now we'll perform a Bayesian fit of the generated histogram, using BAT,\n",
    "to infer the model parameters from the data histogram.\n",
    "\n",
    "In addition to the Julia packages loaded above, we need BAT itself, as\n",
    "well as [IntervalSets](https://github.com/JuliaMath/IntervalSets.jl):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BAT, IntervalSets"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Likelihood Definition\n",
    "\n",
    "First, we need to define a likelihood function for our problem. In BAT,\n",
    "all likelihood functions and priors are subtypes of `BAT.AbstractDensity`.\n",
    "We'll store the histogram that we want to fit in our likelihood density\n",
    "type, as accessing the histogram as a global variable would\n",
    "[reduce performance](https://docs.julialang.org/en/v1/manual/performance-tips/index.html#Avoid-global-variables-1):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct HistogramLikelihood{H<:Histogram,F<:Function} <: AbstractDensity\n",
    "    histogram::H\n",
    "    fitfunc::F\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "As a minimum, BAT requires a method `BAT.density_logval`\n",
    "to be defined for each subtype of `AbstractDensity`.\n",
    "\n",
    "`BAT.density_logval` implements the actual log-likelihood function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function BAT.density_logval(\n",
    "    likelihood::HistogramLikelihood,\n",
    "    params::Union{NamedTuple,AbstractVector{<:Real}}\n",
    ")\n",
    "    # Histogram counts for each bin as an array:\n",
    "    counts = likelihood.histogram.weights\n",
    "\n",
    "    # Histogram binning, has length (length(counts) + 1):\n",
    "    binning = likelihood.histogram.edges[1]\n",
    "\n",
    "    # sum log-likelihood over bins:\n",
    "    log_likelihood::Float64 = 0.0\n",
    "    for i in eachindex(counts)\n",
    "        bin_left, bin_right = binning[i], binning[i+1]\n",
    "        bin_width = bin_right - bin_left\n",
    "        bin_center = (bin_right + bin_left) / 2\n",
    "\n",
    "        observed_counts = counts[i]\n",
    "\n",
    "        # Simple mid-point rule integration of fitfunc over bin:\n",
    "        expected_counts = bin_width * likelihood.fitfunc(params, bin_center)\n",
    "\n",
    "        log_likelihood += logpdf(Poisson(expected_counts), observed_counts)\n",
    "    end\n",
    "\n",
    "    return log_likelihood\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "BAT makes use of Julia's parallel programming facilities if possible, e.g.\n",
    "to run multiple Markov chains in parallel, and expects implementations of\n",
    "`BAT.density_logval` to be thread safe. Mark non-thread-safe code with\n",
    "`@critical` (using Julia package `ParallelProcessingTools`).\n",
    "\n",
    "BAT requires Julia v1.3 or newer to use multi-threading. Support for\n",
    "automatic parallelization across multiple (local and remote) Julia processes\n",
    "is planned, but not implemented yet.\n",
    "\n",
    "Note that Julia currently starts only a single thread by default, you will\n",
    "need to set the environment variable\n",
    "[`JULIA_NUM_THREADS`](https://docs.julialang.org/en/v1/manual/environment-variables/#JULIA_NUM_THREADS-1)\n",
    "to specify the number of Julia threads.\n",
    "\n",
    "Using our likelihood density definition and the histogram to fit, we can now\n",
    "create our data- and fit-function-specific likelihood instance:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "likelihood = HistogramLikelihood(hist, fit_function)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Prior Definition\n",
    "\n",
    "Next, we need to choose a sensible prior for the fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prior = NamedPrior(\n",
    "    a = [0.0..10.0^4, 0.0..10.0^4],\n",
    "    mu = [-2.0..0.0, 1.0..3.0],\n",
    "    sigma = Truncated(Normal(0.4, 2), 0.3, 0.7)\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "In general, BAT allows instances of any subtype of `AbstractDensity` to\n",
    "be uses as a prior, as long as a sampler is defined for it. This way, users\n",
    "may implement complex application-specific priors. You can also\n",
    "use `convert(AbstractDensity, distribution)` to convert any\n",
    "continuous multivariate `Distributions.Distribution` to a\n",
    "`BAT.AbstractDensity` that can be used as a prior (or likelihood).\n",
    "\n",
    "The prior also implies the shapes of the parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using ValueShapes\n",
    "\n",
    "parshapes = valshape(prior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "These will come in handy later on, e.g. to access (the posterior\n",
    "distribution of) individual parameter values."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Bayesian Model Definition\n",
    "\n",
    "Given the likelihood and prior definition, a `BAT.PosteriorDensity` is simply\n",
    "defined via"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "posterior = PosteriorDensity(likelihood, prior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Parameter Space Exploration via MCMC\n",
    "\n",
    "We can now use Markov chain Monte Carlo (MCMC) to explore the space of\n",
    "possible parameter values for the histogram fit.\n",
    "\n",
    "We'll use the Metropolis-Hastings algorithm and a multivariate\n",
    "t-distribution (ν = 1) as it's proposal function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "algorithm = MetropolisHastings(MvTDistProposalSpec(1.0))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We also need to which random number generator and seed to use. BAT requires\n",
    "a counter-based RNG and partitions the RNG space over the MCMC chains. This\n",
    "way, a single RNG seed is sufficient for all chains and results can be\n",
    "reproducible even under parallel execution. Let's choose a Philox4x RNG\n",
    "with a random seed:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rngseed = BAT.Philox4xSeed()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "The algorithm, posterior and RNG seed specify the MCMC chains:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "chainspec = MCMCSpec(algorithm, posterior, rngseed)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's use 4 MCMC chains and require 10^5 unique samples from each chain\n",
    "(after tuning/burn-in):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "nsamples = 10^4\n",
    "nchains = 4"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "BAT provides fine-grained control over the MCMC tuning algorithm,\n",
    "convergence test and the chain initialization and tuning/burn-in strategy\n",
    "(the values used here are the default values):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuner_config = ProposalCovTunerConfig(\n",
    "    λ = 0.5,\n",
    "    α = 0.15..0.35,\n",
    "    β = 1.5,\n",
    "    c = 1e-4..1e2\n",
    ")\n",
    "\n",
    "convergence_test = BGConvergence(\n",
    "    threshold = 1.1,\n",
    "    corrected = false\n",
    ")\n",
    "\n",
    "init_strategy = MCMCInitStrategy(\n",
    "    ninit_tries_per_chain = 8..128,\n",
    "    max_nsamples_pretune = 25,\n",
    "    max_nsteps_pretune = 250,\n",
    "    max_time_pretune = Inf\n",
    ")\n",
    "\n",
    "burnin_strategy = MCMCBurninStrategy(\n",
    "    max_nsamples_per_cycle = 1000,\n",
    "    max_nsteps_per_cycle = 10000,\n",
    "    max_time_per_cycle = Inf,\n",
    "    max_ncycles = 30\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "To increase the verbosity level of BAT logging output, you may want to set\n",
    "the Julia logging level for BAT to debug via `ENV[\"JULIA_DEBUG\"] = \"BAT\"`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ENV[\"JULIA_DEBUG\"] = \"BAT\""
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Now we can generate a set of MCMC samples via `rand`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "samples, sampleids, stats, chains = rand(\n",
    "    chainspec,\n",
    "    nsamples,\n",
    "    nchains,\n",
    "    tuner_config = tuner_config,\n",
    "    convergence_test = convergence_test,\n",
    "    init_strategy = init_strategy,\n",
    "    burnin_strategy = burnin_strategy,\n",
    "    max_nsteps = 10^5,\n",
    "    max_time = Inf,\n",
    "    granularity = 1\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Note: Reasonable default values are defined for all of the above. In many\n",
    "use cases, a simple\n",
    "\n",
    "```julia\n",
    "samples, sampleids, stats, chains =\n",
    "   rand(MCMCSpec(MetropolisHastings(), model), nsamples, nchains)`\n",
    "```\n",
    "\n",
    "may be sufficient."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's print some results:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "println(\"Truth: $true_par_values\")\n",
    "println(\"Mode: $(stats.mode)\")\n",
    "println(\"Mean: $(stats.param_stats.mean)\")\n",
    "println(\"Covariance: $(stats.param_stats.cov)\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "`stats` contains some statistics collected during MCMC sample generation,\n",
    "e.g. the mean and covariance of the parameters and the mode. Equal values\n",
    "for these statistics may of course be calculated afterwards, from the\n",
    "samples:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@assert vec(mean(samples.params, FrequencyWeights(samples.weight))) ≈ stats.param_stats.mean\n",
    "@assert vec(var(samples.params, FrequencyWeights(samples.weight))) ≈ diag(stats.param_stats.cov)\n",
    "@assert cov(samples.params, FrequencyWeights(samples.weight)) ≈ stats.param_stats.cov"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can also, e.g., get the Pearson auto-correlation of the parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "vec(cor(samples.params, FrequencyWeights(samples.weight)))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Visualization of Results"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "BAT.jl comes with an extensive set of plotting recipes for\n",
    "[\"Plots.jl\"] (http://docs.juliaplots.org/latest/).\n",
    "We can plot the marginalized distribution for a single parameter (e.g.\n",
    "parameter 3, i.e. μ₁):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "par_names = [\"a_1\", \"a_2\", \"mu_1\", \"mu_2\", \"sigma\"]\n",
    "plot(\n",
    "    samples, 3,\n",
    "    mean = true, std_dev = true, globalmode = true, localmode = true,\n",
    "    nbins = 50, xlabel = par_names[3], ylabel = \"P($(par_names[3]))\",\n",
    "    title = \"Marginalized Distribution for mu_1\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "or plot the marginalized distribution for a pair of parameters (e.g.\n",
    "parameters 3 and 5, i.e. μ₁ and σ), including information from the parameter\n",
    "stats:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    samples, (3, 5),\n",
    "    mean = true, std_dev = true, globalmode = true, localmode = true,\n",
    "    nbins = 50, xlabel = par_names[3], ylabel = par_names[5],\n",
    "    title = \"Marginalized Distribution for mu_1 and sigma\"\n",
    ")\n",
    "plot!(stats, (3, 5))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can also create an overview plot of the marginalized distribution for all\n",
    "pairs of parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    samples,\n",
    "    mean = false, std_dev = false, globalmode = true, localmode = false,\n",
    "    nbins = 50\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Integration with Tables.jl"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "BAT.jl supports the [Tables.jl](https://github.com/JuliaData/Tables.jl)\n",
    "interface. Using a tables implementation like\n",
    "TypedTables.jl](http://blog.roames.com/TypedTables.jl/stable/),\n",
    "the whole MCMC output (parameter vectors, weights, sample/chain numbers,\n",
    "etc.) can easily can be combined into a single table:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using TypedTables\n",
    "\n",
    "tbl = Table(samples, sampleids)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Using the parameter shapes, we can also generate a table with named\n",
    "parameters instead:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tbl_named = Table(parshapes.(samples), sampleids)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can now, e.g., find the sample with the maximum posterior value (i.e. the\n",
    "mode):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mode_log_posterior, mode_idx = findmax(tbl_named.log_posterior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "And get row `mode_idx` of the table, with all information about the sample\n",
    "at the mode:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Comparison of Truth and Best Fit"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "As a final step, we retrieve the parameter values at the mode, representing\n",
    "the best-fit parameters"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit_par_values = tbl_named[mode_idx].params"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "And plot the truth, data, and best fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    normalize(hist, mode=:density),\n",
    "    st = :steps, label = \"Data\",\n",
    "    title = \"Data, True Model and Best Fit\"\n",
    ")\n",
    "plot!(-4:0.01:4, x -> fit_function(true_par_values, x), label = \"Truth\")\n",
    "plot!(-4:0.01:4, x -> fit_function(fit_par_values, x), label = \"Best fit\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0-rc4.1"
  },
  "kernelspec": {
   "name": "julia-1.3",
   "display_name": "Julia 1.3.0-rc4.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
