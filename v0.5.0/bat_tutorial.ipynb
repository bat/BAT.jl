{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# BAT.jl Tutorial\n",
    "\n",
    "This tutorial demonstrates a simple application of BAT.jl: A Bayesian fit\n",
    "of a histogram with two Gaussian peaks.\n",
    "\n",
    "\n",
    "\n",
    "Note: This tutorial is somewhat verbose, as it aims to be easy to follow for\n",
    "users who are new to Julia. For the same reason, we deliberately avoid making\n",
    "use of Julia features like\n",
    "[closures](https://docs.julialang.org/en/v1/devdocs/functions/#Closures-1),\n",
    "[anonymous functions](https://docs.julialang.org/en/v1/manual/functions/index.html#man-anonymous-functions-1),\n",
    "[broadcasting syntax](https://docs.julialang.org/en/v1/manual/arrays/index.html#Broadcasting-1),\n",
    "[performance annotations](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-annotations-1),\n",
    "etc."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Input Data Generation\n",
    "\n",
    "First, let's generate some synthetic data to fit. We'll need the Julia\n",
    "standard-library packages\n",
    "[\"Random\"](https://docs.julialang.org/en/v1/stdlib/Random/),\n",
    "[\"LinearAlgebra\"](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/)\n",
    "and [\"Statistics\"](https://docs.julialang.org/en/v1/stdlib/Statistics/),\n",
    "as well as the packages\n",
    "[\"Distributions\"](https://juliastats.github.io/Distributions.jl/stable/)\n",
    "and [\"StatsBase\"](http://juliastats.github.io/StatsBase.jl/stable/):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Random, LinearAlgebra, Statistics, Distributions, StatsBase"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "As the underlying truth of our input data/histogram, let us choose an\n",
    "non-normalized probability density composed of two Gaussian peaks with a peak\n",
    "area of 500 and 1000, a mean of -1.0 and 2.0 and a standard error of 0.5"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "data = vcat(\n",
    "    rand(Normal(-1.0, 0.5), 500),\n",
    "    rand(Normal( 2.0, 0.5), 1000)\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "resulting in a vector of floating-point numbers:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "typeof(data) == Vector{Float64}"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Next, we'll create a histogram of that data, this histogram will serve as\n",
    "the input for the Bayesian fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "hist = append!(Histogram(-2:0.1:4), data)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Using the Julia [\"Plots\"](http://docs.juliaplots.org/latest/) package"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "we can plot the histogram:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    normalize(hist, mode=:density),\n",
    "    st = :steps, label = \"Data\",\n",
    "    title = \"Data\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's define our fit function - the function that we expect to describe the\n",
    "data histogram, at each x-Axis position `x`, depending on a given set `p` of\n",
    "model parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function fit_function(p::NamedTuple{(:a, :mu, :sigma)}, x::Real)\n",
    "    p.a[1] * pdf(Normal(p.mu[1], p.sigma), x) +\n",
    "    p.a[2] * pdf(Normal(p.mu[2], p.sigma), x)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "The fit parameters (model parameters) `a` (peak areas) and `mu` (peak means)\n",
    "are vectors, parameter `sigma` (peak width) is a scalar, we assume it's the\n",
    "same for both Gaussian peaks.\n",
    "\n",
    "The true values for the model/fit parameters are the values we used to\n",
    "generate the data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "true_par_values = (a = [500, 1000], mu = (-1.0, 2.0), sigma = 0.5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's visually compare the histogram and the fit function, using these true\n",
    "parameter values, to make sure everything is set up correctly:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    normalize(hist, mode=:density),\n",
    "    st = :steps, label = \"Data\",\n",
    "    title = \"Data and True Statistical Model\"\n",
    ")\n",
    "plot!(\n",
    "    -4:0.01:4, x -> fit_function(true_par_values, x),\n",
    "    label = \"Truth\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Bayesian Fit\n",
    "\n",
    "Now we'll perform a Bayesian fit of the generated histogram, using BAT,\n",
    "to infer the model parameters from the data histogram.\n",
    "\n",
    "In addition to the Julia packages loaded above, we need BAT itself, as\n",
    "well as [IntervalSets](https://github.com/JuliaMath/IntervalSets.jl):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BAT, IntervalSets"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Likelihood Definition\n",
    "\n",
    "First, we need to define the likelihood (function) for our problem.\n",
    "\n",
    "BAT represents densities like likelihoods and priors as subtypes of\n",
    "`BAT.AbstractDensity`. Custom likelihood can be defined by\n",
    "creating a new subtype of `AbstractDensity` and by implementing (at minimum)\n",
    "`BAT.density_logval` for that type - in complex uses cases, this may become\n",
    "necessary. Typically, however, it is sufficient to define a custom\n",
    "likelihood as a simple function that returns the log-likelihood value for\n",
    "a given set of parameters. BAT will automatically convert such a\n",
    "log-likelihood function into a subtype of `AbstractDensity`.\n",
    "\n",
    "For performance reasons, functions should [not access global variables\n",
    "directly] (https://docs.julialang.org/en/v1/manual/performance-tips/index.html#Avoid-global-variables-1).\n",
    "So we'll use an [anonymous function](https://docs.julialang.org/en/v1/manual/functions/#man-anonymous-functions-1)\n",
    "inside of a [let-statement](https://docs.julialang.org/en/v1/base/base/#let)\n",
    "to capture the value of the global variable `hist` in a local variable `h`\n",
    "(and to shorten function name `fit_function` to `f`, purely for\n",
    "convenience):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "log_likelihood = let h = hist, f = fit_function\n",
    "    params -> begin\n",
    "        # Histogram counts for each bin as an array:\n",
    "        counts = h.weights\n",
    "\n",
    "        # Histogram binning, has length (length(counts) + 1):\n",
    "        binning = h.edges[1]\n",
    "\n",
    "        # sum log-likelihood value over bins:\n",
    "        ll_value::Float64 = 0.0\n",
    "        for i in eachindex(counts)\n",
    "            # Get information about current bin:\n",
    "            bin_left, bin_right = binning[i], binning[i+1]\n",
    "            bin_width = bin_right - bin_left\n",
    "            bin_center = (bin_right + bin_left) / 2\n",
    "\n",
    "            observed_counts = counts[i]\n",
    "\n",
    "            # Simple mid-point rule integration of fit function `f` over bin:\n",
    "            expected_counts = bin_width * f(params, bin_center)\n",
    "\n",
    "            # Add log of Poisson probability for bin:\n",
    "            ll_value += logpdf(Poisson(expected_counts), observed_counts)\n",
    "        end\n",
    "\n",
    "        return ll_value\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "BAT makes use of Julia's parallel programming facilities if possible, e.g.\n",
    "to run multiple Markov chains in parallel. Therefore, log-likelihood\n",
    "(and other) code must be thread-safe. Mark non-thread-safe code with\n",
    "`@critical` (provided by Julia package `ParallelProcessingTools`).\n",
    "\n",
    "BAT requires Julia v1.3 or newer to use multi-threading. Support for\n",
    "automatic parallelization across multiple (local and remote) Julia processes\n",
    "is planned, but not implemented yet.\n",
    "\n",
    "Note that Julia currently starts only a single thread by default. Set the\n",
    "the environment variable\n",
    "[`JULIA_NUM_THREADS`](https://docs.julialang.org/en/v1/manual/environment-variables/#JULIA_NUM_THREADS-1)\n",
    "to specify the desired number of Julia threads."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can evaluate `log_likelihood`, e.g. for the true parameter values:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "log_likelihood(true_par_values)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Prior Definition\n",
    "\n",
    "Next, we need to choose a sensible prior for the fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prior = NamedTupleDist(\n",
    "    a = [0.0..10.0^4, 0.0..10.0^4],\n",
    "    mu = [-2.0..0.0, 1.0..3.0],\n",
    "    sigma = Truncated(Normal(0.4, 2), 0.3, 0.7)\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "In general, BAT allows instances of any subtype of `AbstractDensity` to\n",
    "be uses as a prior, as long as a sampler is defined for it. This way, users\n",
    "may implement complex application-specific priors. You can also\n",
    "use `convert(AbstractDensity, distribution)` to convert any\n",
    "continuous multivariate `Distributions.Distribution` to a\n",
    "`BAT.AbstractDensity` that can be used as a prior (or likelihood).\n",
    "\n",
    "The prior also implies the shapes of the parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using ValueShapes\n",
    "\n",
    "parshapes = valshape(prior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "These will come in handy later on, e.g. to access (the posterior\n",
    "distribution of) individual parameter values."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Bayesian Model Definition\n",
    "\n",
    "Given the likelihood and prior definition, a `BAT.PosteriorDensity` is simply\n",
    "defined via"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "posterior = PosteriorDensity(log_likelihood, prior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Parameter Space Exploration via MCMC\n",
    "\n",
    "We can now use Markov chain Monte Carlo (MCMC) to explore the space of\n",
    "possible parameter values for the histogram fit.\n",
    "\n",
    "To increase the verbosity level of BAT logging output, you may want to set\n",
    "the Julia logging level for BAT to debug via `ENV[\"JULIA_DEBUG\"] = \"BAT\"`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ENV[\"JULIA_DEBUG\"] = \"BAT\""
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's use 4 MCMC chains and require 10^5 unique samples from each chain\n",
    "(after tuning/burn-in):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "nsamples = 10^4\n",
    "nchains = 4"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Now we can generate a set of MCMC samples via `bat_sample`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "samples = bat_sample(posterior, (nsamples, nchains), MetropolisHastings())\n",
    "nothing # hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's calculate some posterior statistics using the function\n",
    "`bat_stats` and print the results:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "stats = bat_stats(samples)\n",
    "\n",
    "println(\"Truth: $true_par_values\")\n",
    "println(\"Mode: $(stats.mode)\")\n",
    "println(\"Mean: $(stats.mean)\")\n",
    "println(\"Covariance: $(stats.cov)\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can also, e.g., get the Pearson auto-correlation of the parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cor(samples.params, FrequencyWeights(samples.weight))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Visualization of Results"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "BAT.jl comes with an extensive set of plotting recipes for\n",
    "[\"Plots.jl\"] (http://docs.juliaplots.org/latest/).\n",
    "We can plot the marginalized distribution for a single parameter (e.g.\n",
    "parameter 3, i.e. μ₁):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "par_names = [\"a_1\", \"a_2\", \"mu_1\", \"mu_2\", \"sigma\"]\n",
    "plot(\n",
    "    samples, 3,\n",
    "    mean = true, std_dev = true, globalmode = true, localmode = true,\n",
    "    nbins = 50, xlabel = par_names[3], ylabel = \"P($(par_names[3]))\",\n",
    "    title = \"Marginalized Distribution for mu_1\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "or plot the marginalized distribution for a pair of parameters (e.g.\n",
    "parameters 3 and 5, i.e. μ₁ and σ), including information from the parameter\n",
    "stats:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    samples, (3, 5),\n",
    "    mean = true, std_dev = true, globalmode = true, localmode = true,\n",
    "    nbins = 50, xlabel = par_names[3], ylabel = par_names[5],\n",
    "    title = \"Marginalized Distribution for mu_1 and sigma\"\n",
    ")\n",
    "plot!(MCMCBasicStats(samples), (3, 5))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can also create an overview plot of the marginalized distribution for all\n",
    "pairs of parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    samples,\n",
    "    mean = false, std_dev = false, globalmode = true, localmode = false,\n",
    "    nbins = 50\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Integration with Tables.jl"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "BAT.jl supports the [Tables.jl](https://github.com/JuliaData/Tables.jl)\n",
    "interface. So we can also convert the vector of MCMC samples vecto a\n",
    "table, e.g. using TypedTables.jl](http://blog.roames.com/TypedTables.jl/stable/):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using TypedTables\n",
    "\n",
    "tbl = Table(samples)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Using the parameter shapes, we can generate a table with named parameters,\n",
    "instead of flat real-valued parameter vectors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tbl_named = parshapes.(samples)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can now, e.g., find the sample with the maximum posterior value (i.e. the\n",
    "mode):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mode_log_posterior, mode_idx = findmax(tbl_named.log_posterior)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "And get row `mode_idx` of the table, with all information about the sample\n",
    "at the mode:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Comparison of Truth and Best Fit"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "As a final step, we retrieve the parameter values at the mode, representing\n",
    "the best-fit parameters"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit_par_values = tbl_named[mode_idx].params"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "And plot the truth, data, and best fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    normalize(hist, mode=:density),\n",
    "    st = :steps, label = \"Data\",\n",
    "    title = \"Data, True Model and Best Fit\"\n",
    ")\n",
    "plot!(-4:0.01:4, x -> fit_function(true_par_values, x), label = \"Truth\")\n",
    "plot!(-4:0.01:4, x -> fit_function(fit_par_values, x), label = \"Best fit\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Fine-grained control\n",
    "\n",
    "BAT provides fine-grained control over the MCMC algorithm options, the\n",
    "MCMC chain initialization, tuning/burn-in strategy and convergence testing.\n",
    "All option value used in the following are the default values, any or all\n",
    "may be omitted."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We'll sample using the The Metropolis-Hastings MCMC algorithm. By default,\n",
    "BAT uses a multivariate t-distribution (ν = 1) as the proposal function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "algorithm = MetropolisHastings(MvTDistProposal(1.0))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "BAT requires a counter-based random number generator (RNG), since it\n",
    "partitions the RNG space over the MCMC chains. This way, a single RNG seed\n",
    "is sufficient for all chains and results are reproducible even under\n",
    "parallel execution. By default, BAT uses a Philox4x RNG initialized with a\n",
    "random seed drawn from the\n",
    "[system entropy pool](https://docs.julialang.org/en/v1/stdlib/Random/index.html#Random.RandomDevice):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Random123\n",
    "rng = Philox4x()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Other default parameters are:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuning = AdaptiveMetropolisTuning(\n",
    "    λ = 0.5,\n",
    "    α = 0.15..0.35,\n",
    "    β = 1.5,\n",
    "    c = 1e-4..1e2\n",
    ")\n",
    "\n",
    "convergence = BrooksGelmanConvergence(\n",
    "    threshold = 1.1,\n",
    "    corrected = false\n",
    ")\n",
    "\n",
    "init = MCMCInitStrategy(\n",
    "    ninit_tries_per_chain = 8..128,\n",
    "    max_nsamples_pretune = 25,\n",
    "    max_nsteps_pretune = 250,\n",
    "    max_time_pretune = Inf\n",
    ")\n",
    "\n",
    "burnin = MCMCBurninStrategy(\n",
    "    max_nsamples_per_cycle = 1000,\n",
    "    max_nsteps_per_cycle = 10000,\n",
    "    max_time_per_cycle = Inf,\n",
    "    max_ncycles = 30\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "To generate MCMC samples with explicit control over all options, use"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "samples = bat_sample(\n",
    "    rng, posterior, (nsamples, nchains), algorithm,\n",
    "    max_nsteps = 10 * nsamples,\n",
    "    max_time = Inf,\n",
    "    tuning = tuning,\n",
    "    init = init,\n",
    "    burnin = burnin,\n",
    "    convergence = convergence,\n",
    "    strict = false,\n",
    "    filter = true\n",
    ")\n",
    "nothing # hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "However, in many use cases, simply using the default options via\n",
    "\n",
    "```julia\n",
    "samples = bat_sample(posterior, (nsamples, nchains), MetropolisHastings())\n",
    "```\n",
    "\n",
    "will often be sufficient."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0-rc4.1"
  },
  "kernelspec": {
   "name": "julia-1.3",
   "display_name": "Julia 1.3.0-rc4.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
